# Large Language Models and Traditional Machine Learning: Comparative Analysis and Model Merging for the Prediction of Four ICU Adverse Events from Structured Data

Abstract: 
Large language models (LLMs) show promise in medicine, but their performance on disease prediction from structured clinical data remains unclear. Using MIMIC-IV and 34 physiological variables, this study compared seven traditional machine-learning (ML) models with five mainstream LLMs on four ICU prediction tasks. Overall, Traditional ML consistently outperformed LLMs, with XGBoost achieving the best AUROC in all tasks and exceeding the strongest LLM: mortality 0.870 vs 0.820, hemorrhagic shock 0.829 vs 0.673, hypoxemia 0.798 vs 0.719, and MODS 0.850 vs 0.801. ML models also showed better calibration and higher net clinical benefit across decision thresholds. These findings indicate that, for prediction of four critical ICU adverse events from structured data, current LLMs cannot yet replace well-validated traditional ML algorithms. To bridge this gap, we further propose a merging strategy that combines the high-precision quantitative predictions of ML models with the rich clinical knowledge and natural language interaction capabilities of LLMs. Validation results show that the merged model preserves strong discriminative performance while providing clinically grounded rationale and actionable recommendations. Consequently, this merging architecture offers a practical pathway toward more intelligent and interpretable clinical decision support.
